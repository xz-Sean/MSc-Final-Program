{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd184c7",
   "metadata": {},
   "source": [
    "# Data Unifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0991b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd1063",
   "metadata": {},
   "source": [
    "## 1. aler_1996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53b417e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/mult_var_blast.xlsx  (sheet='aler_1996')\n",
      "Original shape : (33, 17)\n",
      "\n",
      "== dtypes ==\n",
      "mine            object\n",
      "blast           object\n",
      "L[m]           float64\n",
      "R[m]             int64\n",
      "S/B            float64\n",
      "SxB[m²]        float64\n",
      "PF[kg/m³]      float64\n",
      "Eb[kg/m³]      float64\n",
      "Ec[kg/m³]      float64\n",
      "De[ms]           int64\n",
      "Xcr[m]         float64\n",
      "Xcp[m]         float64\n",
      "FI             float64\n",
      "group           object\n",
      "Unnamed: 14    float64\n",
      "variable        object\n",
      "OBS             object\n",
      "dtype: object\n",
      "\n",
      "== descriptive statistics (numeric only) ==\n",
      "             count       mean        std     min      25%      50%      75%  \\\n",
      "L[m]          33.0  11.272727   4.220654  7.5000   7.5000  10.0000  12.5000   \n",
      "R[m]          33.0   4.181818   2.888063  1.0000   3.0000   3.0000   7.0000   \n",
      "S/B           33.0   1.200606   0.038319  1.1300   1.1700   1.2000   1.2400   \n",
      "SxB[m²]       33.0  26.754545  12.828608  7.5000  25.2000  25.2000  42.0000   \n",
      "PF[kg/m³]     33.0   0.356767   0.075420  0.2165   0.3030   0.3397   0.4112   \n",
      "Eb[kg/m³]     33.0   0.059421   0.094805  0.0000   0.0030   0.0167   0.0896   \n",
      "Ec[kg/m³]     33.0   0.297352   0.129183  0.0000   0.2698   0.3047   0.3640   \n",
      "De[ms]        33.0  21.818182  25.304958  0.0000   0.0000  10.0000  40.0000   \n",
      "Xcr[m]        33.0   1.424836   0.512851  0.5770   1.0810   1.5630   2.0000   \n",
      "Xcp[m]        33.0   0.654842   0.237305  0.2980   0.4870   0.5980   0.8110   \n",
      "FI            33.0   2.260909   0.715286  1.1400   1.7200   2.3200   2.6900   \n",
      "Unnamed: 14    0.0        NaN        NaN     NaN      NaN      NaN      NaN   \n",
      "\n",
      "                 max  \n",
      "L[m]         18.0000  \n",
      "R[m]         12.0000  \n",
      "S/B           1.2400  \n",
      "SxB[m²]      42.0000  \n",
      "PF[kg/m³]     0.4797  \n",
      "Eb[kg/m³]     0.3620  \n",
      "Ec[kg/m³]     0.4630  \n",
      "De[ms]       75.0000  \n",
      "Xcr[m]        2.3290  \n",
      "Xcp[m]        1.3750  \n",
      "FI            3.7300  \n",
      "Unnamed: 14      NaN  \n",
      "Raw Excel saved aler_1996_raw.xlsx\n",
      "Clean Excel saved: aler_1996_clean.xlsx\n",
      "Markdown report written -> aler_1996_report.md\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Clean & unify the 'aler_1996' sheet from mult_var_blast.xlsx\n",
    "1. Read Excel document (sheet='aler_1996')\n",
    "2. Display basic info & descriptive statistics\n",
    "3. Rename columns via column_map; apply unit conversions via unit_coef\n",
    "4. Select the Golden-12 + extra columns\n",
    "5. Save raw / clean data as Excel; generate a brief Markdown report\n",
    "\"\"\"\n",
    "\n",
    "# Parameters\n",
    "INPUT_FILE = Path(\"data/mult_var_blast.xlsx\")   # source workbook\n",
    "SHEET_NAME = \"aler_1996\"                        # sheet to read\n",
    "RAW_OUT = Path(\"aler_1996_raw.xlsx\")            # raw dump\n",
    "CLEAN_OUT = Path(\"aler_1996_clean.xlsx\")        # unified version\n",
    "REPORT_MD = Path(\"aler_1996_report.md\")         # markdown summary\n",
    "\n",
    "# Column mapping: original to unified\n",
    "column_map = {\n",
    "    \"mine\"      : \"site\",\n",
    "    \"blast\"     : \"blast_id\",\n",
    "    \"L[m]\"      : \"hole_length_m\",\n",
    "    \"R[m]\"      : \"num_rows\",\n",
    "    \"S/B\"       : \"spacing_over_burden\",\n",
    "    \"SxB[m²]\"   : \"mesh_area_m2\",\n",
    "    \"PF[kg/m³]\" : \"powder_factor\",\n",
    "    \"Eb[kg/m³]\" : \"bottom_energy\",\n",
    "    \"Ec[kg/m³]\" : \"column_energy\",\n",
    "    \"De[ms]\"    : \"delay_ms\",\n",
    "    \"Xcr[m]\"    : \"in_situ_char_size_m\",\n",
    "    \"Xcp[m]\"    : \"muckpile_char_size_m\",\n",
    "    \"FI\"        : \"fragmentation_index\",\n",
    "    \"group\"     : \"group\",\n",
    "}\n",
    "\n",
    "# Optional unit conversions\n",
    "unit_coef = {\n",
    "    # \"delay_ms\": 0.001. \n",
    "    # However, 'delay' is not selected column.\n",
    "}\n",
    "\n",
    "# Golden-12 unified feature list\n",
    "golden12 = [\n",
    "    \"site\", \"blast_id\",\n",
    "    \"spacing_over_burden\",        # S/B\n",
    "    \"benchheight_over_burden\",    # H/B  (missing here)\n",
    "    \"burden_over_diameter\",       # B/D  (missing here)\n",
    "    \"stemming_over_burden\",       # T/B  (missing here)\n",
    "    \"powder_factor\",\n",
    "    \"youngs_modulus_gpa\",         # missing\n",
    "    \"fragment_median_m\",          # missing\n",
    "    \"fragmentation_index\",        # FI\n",
    "    \"group\",\n",
    "    \"mesh_area_m2\",\n",
    "]\n",
    "\n",
    "# 1. Load the sheet\n",
    "print(f\"Reading {INPUT_FILE}  (sheet='{SHEET_NAME}')\")\n",
    "df_raw = pd.read_excel(INPUT_FILE, sheet_name=SHEET_NAME)\n",
    "print(\"Original shape :\", df_raw.shape)\n",
    "\n",
    "# 2. Quick diagnostics\n",
    "print(\"\\n== dtypes ==\")\n",
    "print(df_raw.dtypes)\n",
    "print(\"\\n== descriptive statistics (numeric only) ==\")\n",
    "print(df_raw.describe().T)\n",
    "\n",
    "# 3. Rename & unit conversion\n",
    "df = df_raw.rename(columns=column_map, errors=\"ignore\")\n",
    "\n",
    "for col, coef in unit_coef.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col] * coef\n",
    "\n",
    "# 4. Select & save data\n",
    "# Save the untouched sheet (raw) for archival\n",
    "df_raw.to_excel(RAW_OUT, index=False)\n",
    "print(f\"Raw Excel saved {RAW_OUT}\")\n",
    "\n",
    "# Existing columns：df[\"spacing_over_burden\"](r) & df[\"mesh_area_m2\"](A)\n",
    "mask = df[\"spacing_over_burden\"].notna() & df[\"mesh_area_m2\"].notna()\n",
    "if mask.any():\n",
    "    r = df.loc[mask, \"spacing_over_burden\"]   # ratio S/B\n",
    "    A = df.loc[mask, \"mesh_area_m2\"]          # mesh area S×B\n",
    "    df.loc[mask, \"burden_m\"]  = (A / r) ** 0.5\n",
    "    df.loc[mask, \"spacing_m\"] = (A * r) ** 0.5\n",
    "\n",
    "if \"muckpile_char_size_m\" in df.columns:\n",
    "    df[\"fragment_median_m\"] = df[\"muckpile_char_size_m\"]\n",
    "\n",
    "for col in golden12:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "\n",
    "df_clean = df[golden12]\n",
    "df_clean.to_excel(CLEAN_OUT, index=False)\n",
    "print(f\"Clean Excel saved: {CLEAN_OUT}\")\n",
    "\n",
    "# 5. Generate Markdown report\n",
    "missing_rate = df_clean.isna().mean().rename(\"missing_ratio\")\n",
    "describe = df_clean.describe(include=\"all\").T\n",
    "report_tbl = pd.concat([describe, missing_rate], axis=1)\n",
    "\n",
    "md_lines = [\n",
    "    \"# Aler 1996 - cleaning report\",\n",
    "    \"\",\n",
    "    f\"* source file : `{INPUT_FILE}`\",\n",
    "    f\"* original shape : {df_raw.shape}\",\n",
    "    f\"* clean shape    : {df_clean.shape}\",\n",
    "    \"\",\n",
    "    \"## Missing-rate & descriptive stats (Golden-12)\",\n",
    "    report_tbl.to_markdown(),\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "REPORT_MD.write_text(\"\\n\".join(md_lines), encoding=\"utf-8\")\n",
    "print(f\"Markdown report written -> {REPORT_MD}\")\n",
    "\n",
    "print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4547e6e",
   "metadata": {},
   "source": [
    "## 2. kulatilake_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4669bc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/mult_var_blast.xlsx (sheet='kulatilake_2010')\n",
      "Original shape : (90, 18)\n",
      "\n",
      "== dtypes ==\n",
      "site            object\n",
      "S/B            float64\n",
      "H/B            float64\n",
      "B/D            float64\n",
      "T/B            float64\n",
      "PF[kg/m³]      float64\n",
      "xB[m]          float64\n",
      "E[Gpa]         float64\n",
      "x50[m]         float64\n",
      "FI             float64\n",
      "group           object\n",
      "ssB[1/m]       float64\n",
      "ss50[1/m]      float64\n",
      "Unnamed: 13    float64\n",
      "variable        object\n",
      "OBS            float64\n",
      "Unnamed: 16    float64\n",
      "n              float64\n",
      "dtype: object\n",
      "\n",
      "== descriptive stats (numeric only) ==\n",
      "             count       mean        std        min        25%        50%  \\\n",
      "S/B           90.0   1.201778   0.110134   1.000000   1.160000   1.200000   \n",
      "H/B           90.0   3.458889   1.638696   1.330000   2.400000   3.190000   \n",
      "B/D           90.0  27.216333   4.798088  17.980000  24.720000  27.270000   \n",
      "T/B           90.0   1.267556   0.691722   0.500000   0.830000   1.130000   \n",
      "PF[kg/m³]     90.0   0.536556   0.239227   0.220000   0.350000   0.480000   \n",
      "xB[m]         90.0   1.178667   0.479209   0.290000   0.830000   1.080000   \n",
      "E[Gpa]        90.0  30.585333  17.755830   9.570000  15.475000  24.450000   \n",
      "x50[m]        90.0   0.315667   0.185576   0.120000   0.170000   0.245000   \n",
      "FI            90.0   4.725585   3.003641   1.315789   2.642857   3.594670   \n",
      "ssB[1/m]      90.0   9.376763   4.289738   4.239001   6.140435   8.563196   \n",
      "ss50[1/m]     90.0  33.171692  14.309047   9.525753  20.345908  32.769645   \n",
      "Unnamed: 13    0.0        NaN        NaN        NaN        NaN        NaN   \n",
      "OBS            0.0        NaN        NaN        NaN        NaN        NaN   \n",
      "Unnamed: 16    0.0        NaN        NaN        NaN        NaN        NaN   \n",
      "n              1.0   1.500000        NaN   1.500000   1.500000   1.500000   \n",
      "\n",
      "                   75%        max  \n",
      "S/B           1.250000   1.750000  \n",
      "H/B           4.800000   6.820000  \n",
      "B/D          30.300000  39.470000  \n",
      "T/B           1.390000   4.670000  \n",
      "PF[kg/m³]     0.682500   1.260000  \n",
      "xB[m]         1.560000   2.350000  \n",
      "E[Gpa]       45.000000  60.000000  \n",
      "x50[m]        0.415000   0.960000  \n",
      "FI            6.223214  15.666667  \n",
      "ssB[1/m]     10.865569  28.124413  \n",
      "ss50[1/m]    45.589311  62.470166  \n",
      "Unnamed: 13        NaN        NaN  \n",
      "OBS                NaN        NaN  \n",
      "Unnamed: 16        NaN        NaN  \n",
      "n             1.500000   1.500000  \n",
      "Raw Excel saved: kulatilake_2010_raw.xlsx\n",
      "Clean Excel saved: kulatilake_2010_clean.xlsx\n",
      "Markdown report written -> kulatilake_2010_report.md\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Clean & unify the 'kulatilake_2010' sheet from mult_var_blast.xlsx\n",
    "Same logic as previous one ('aler_1996')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Parameters\n",
    "INPUT_FILE  = Path(\"data/mult_var_blast.xlsx\")\n",
    "SHEET_NAME  = \"kulatilake_2010\"\n",
    "RAW_OUT     = Path(\"kulatilake_2010_raw.xlsx\")\n",
    "CLEAN_OUT   = Path(\"kulatilake_2010_clean.xlsx\")\n",
    "REPORT_MD   = Path(\"kulatilake_2010_report.md\")\n",
    "\n",
    "# Column mapping: original to unified\n",
    "column_map = {\n",
    "    \"site\"          : \"site\",\n",
    "    \"S/B\"           : \"spacing_over_burden\",\n",
    "    \"H/B\"           : \"benchheight_over_burden\",\n",
    "    \"B/D\"           : \"burden_over_diameter\",\n",
    "    \"T/B\"           : \"stemming_over_burden\",\n",
    "    \"PF[kg/m³]\"     : \"powder_factor\",\n",
    "    \"xB[m]\"         : \"x_burden_pred_m\",\n",
    "    \"E[Gpa]\"        : \"youngs_modulus_gpa\",\n",
    "    \"x50[m]\"        : \"fragment_median_m\",\n",
    "    \"FI\"            : \"fragmentation_index\",\n",
    "    \"group\"         : \"group\",\n",
    "    \"ssB[1/m]\"      : \"specific_surface_burden\",   # = 6/B\n",
    "    \"ss50[1/m]\"     : \"specific_surface_x50\",      # = 6/x50\n",
    "}\n",
    "\n",
    "unit_coef = {}            \n",
    "\n",
    "golden12 = [\n",
    "    \"site\", \"blast_id\",               # No blast_id -> NaN\n",
    "    \"spacing_over_burden\",\n",
    "    \"benchheight_over_burden\",\n",
    "    \"burden_over_diameter\",\n",
    "    \"stemming_over_burden\",\n",
    "    \"powder_factor\",\n",
    "    \"youngs_modulus_gpa\",\n",
    "    \"fragment_median_m\",\n",
    "    \"fragmentation_index\",\n",
    "    \"group\",\n",
    "    \"mesh_area_m2\",                   # Not exist -> NaN\n",
    "]\n",
    "\n",
    "# 1. Load \n",
    "print(f\"Reading {INPUT_FILE} (sheet='{SHEET_NAME}')\")\n",
    "df_raw = pd.read_excel(INPUT_FILE, sheet_name=SHEET_NAME)\n",
    "print(\"Original shape :\", df_raw.shape)\n",
    "\n",
    "# 2. Diagnostics\n",
    "print(\"\\n== dtypes ==\")\n",
    "print(df_raw.dtypes)\n",
    "print(\"\\n== descriptive stats (numeric only) ==\")\n",
    "print(df_raw.describe().T)\n",
    "\n",
    "# 3. Rename & unit convert\n",
    "df = df_raw.rename(columns=column_map, errors=\"ignore\")\n",
    "for col, coef in unit_coef.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col] * coef\n",
    "\n",
    "# 3-a.  derive B, S, fragment_median from ssB / ss50\n",
    "# (1) derive burden & spacing  (ssB = 6 / B)\n",
    "if {\"specific_surface_burden\", \"spacing_over_burden\"}.issubset(df.columns):\n",
    "    mask = df[\"specific_surface_burden\"].notna() & df[\"spacing_over_burden\"].notna()\n",
    "    if mask.any():\n",
    "        B = 6.0 / df.loc[mask, \"specific_surface_burden\"]\n",
    "        r = df.loc[mask, \"spacing_over_burden\"]\n",
    "        df.loc[mask, \"burden_m\"]  = B\n",
    "        df.loc[mask, \"spacing_m\"] = r * B            # S = (S/B) × B\n",
    "\n",
    "# (2) derive fragment_median_m if missing and ss50 present\n",
    "if \"fragment_median_m\" not in df.columns and \"specific_surface_x50\" in df.columns:\n",
    "    df[\"fragment_median_m\"] = 6.0 / df[\"specific_surface_x50\"]\n",
    "\n",
    "# 4. Save raw & clean\n",
    "df_raw.to_excel(RAW_OUT, index=False)\n",
    "print(f\"Raw Excel saved: {RAW_OUT}\")\n",
    "\n",
    "# guarantee Golden-12 columns\n",
    "for col in golden12:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "df_clean = df[golden12]\n",
    "df_clean.to_excel(CLEAN_OUT, index=False)\n",
    "print(f\"Clean Excel saved: {CLEAN_OUT}\")\n",
    "\n",
    "# 5. Markdown report\n",
    "missing_rate = df_clean.isna().mean().rename(\"missing_ratio\")\n",
    "report_tbl   = pd.concat([df_clean.describe(include=\"all\").T, missing_rate], axis=1)\n",
    "\n",
    "md_lines = [\n",
    "    \"# kulatilake 2010 - cleaning report\",\n",
    "    \"\",\n",
    "    f\"* source file : `{INPUT_FILE}`\",\n",
    "    f\"* original shape : {df_raw.shape}\",\n",
    "    f\"* clean shape    : {df_clean.shape}\",\n",
    "    \"\",\n",
    "    \"## Missing-rate & descriptive stats (Golden-12)\",\n",
    "    report_tbl.to_markdown(),\n",
    "    \"\",\n",
    "]\n",
    "REPORT_MD.write_text(\"\\n\".join(md_lines), encoding=\"utf-8\")\n",
    "print(f\"Markdown report written -> {REPORT_MD}\")\n",
    "\n",
    "print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de249b51",
   "metadata": {},
   "source": [
    "## 3. hudaverdi_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd0289dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/mult_var_blast.xlsx (sheet='hudaverdi_2010')\n",
      "Original shape : (97, 18)\n",
      "\n",
      "== dtypes ==\n",
      "site            object\n",
      "S/B            float64\n",
      "H/B            float64\n",
      "B/D            float64\n",
      "T/B            float64\n",
      "PF[kg/m³]      float64\n",
      "xB[m]          float64\n",
      "E[Gpa]         float64\n",
      "x50[m]         float64\n",
      "FI             float64\n",
      "group           object\n",
      "ssB[1/m]       float64\n",
      "ss50[1/m]      float64\n",
      "Unnamed: 13    float64\n",
      "variable        object\n",
      "OBS            float64\n",
      "Unnamed: 16    float64\n",
      "n              float64\n",
      "dtype: object\n",
      "\n",
      "== descriptive stats (numeric only) ==\n",
      "             count       mean        std        min        25%        50%  \\\n",
      "S/B           97.0   1.188969   0.116766   1.000000   1.140000   1.200000   \n",
      "H/B           97.0   3.345155   1.633681   1.330000   1.830000   2.830000   \n",
      "B/D           97.0  27.354948   4.838572  17.980000  24.720000  27.270000   \n",
      "T/B           97.0   1.262784   0.673895   0.500000   0.830000   1.140000   \n",
      "PF[kg/m³]     97.0   0.529175   0.235455   0.220000   0.350000   0.480000   \n",
      "xB[m]         97.0   1.106701   0.532274   0.020000   0.730000   1.030000   \n",
      "E[Gpa]        97.0  29.460619  17.878817   9.570000  15.000000  16.900000   \n",
      "x50[m]        97.0   0.302577   0.188388   0.020000   0.160000   0.230000   \n",
      "FI            97.0   4.473743   3.031881   1.000000   2.432432   3.351351   \n",
      "ssB[1/m]      97.0  15.598077  33.796818   4.239001   6.140435   8.938297   \n",
      "ss50[1/m]     97.0  38.343912  33.360951   9.525753  21.026658  34.684198   \n",
      "Unnamed: 13    0.0        NaN        NaN        NaN        NaN        NaN   \n",
      "OBS            0.0        NaN        NaN        NaN        NaN        NaN   \n",
      "Unnamed: 16    0.0        NaN        NaN        NaN        NaN        NaN   \n",
      "n              1.0   1.500000        NaN   1.500000   1.500000   1.500000   \n",
      "\n",
      "                   75%         max  \n",
      "S/B           1.250000    1.750000  \n",
      "H/B           4.750000    6.820000  \n",
      "B/D          30.300000   39.470000  \n",
      "T/B           1.400000    4.670000  \n",
      "PF[kg/m³]     0.660000    1.260000  \n",
      "xB[m]         1.560000    2.350000  \n",
      "E[Gpa]       45.000000   60.000000  \n",
      "x50[m]        0.400000    0.960000  \n",
      "FI            6.058824   15.666667  \n",
      "ssB[1/m]     12.203339  315.826695  \n",
      "ss50[1/m]    48.158779  315.826695  \n",
      "Unnamed: 13        NaN         NaN  \n",
      "OBS                NaN         NaN  \n",
      "Unnamed: 16        NaN         NaN  \n",
      "n             1.500000    1.500000  \n",
      "Raw Excel saved: hudaverdi_2010_raw.xlsx\n",
      "Clean Excel saved: hudaverdi_2010_clean.xlsx\n",
      "Markdown report written -> hudaverdi_2010_report.md\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Clean & unify the 'hudaverdi_2010' sheet from mult_var_blast.xlsx\n",
    "\"\"\"\n",
    "\n",
    "# Parameters\n",
    "INPUT_FILE = Path(\"data/mult_var_blast.xlsx\")\n",
    "SHEET_NAME = \"hudaverdi_2010\"\n",
    "\n",
    "RAW_OUT   = Path(\"hudaverdi_2010_raw.xlsx\")\n",
    "CLEAN_OUT = Path(\"hudaverdi_2010_clean.xlsx\")\n",
    "REPORT_MD = Path(\"hudaverdi_2010_report.md\")\n",
    "\n",
    "# Column mapping: original to unified\n",
    "column_map = {\n",
    "    \"site\"          : \"site\",\n",
    "    # No blast_id -> NaN\n",
    "    \"S/B\"           : \"spacing_over_burden\",\n",
    "    \"H/B\"           : \"benchheight_over_burden\",\n",
    "    \"B/D\"           : \"burden_over_diameter\",\n",
    "    \"T/B\"           : \"stemming_over_burden\",\n",
    "    \"PF[kg/m³]\"     : \"powder_factor\",\n",
    "    \"xB[m]\"         : \"x_burden_pred_m\",\n",
    "    \"E[Gpa]\"        : \"youngs_modulus_gpa\",\n",
    "    \"x50[m]\"        : \"fragment_median_m\",\n",
    "    \"FI\"            : \"fragmentation_index\",\n",
    "    \"group\"         : \"group\",\n",
    "    \"ssB[1/m]\"      : \"specific_surface_burden\",   # 6 / B\n",
    "    \"ss50[1/m]\"     : \"specific_surface_x50\",      # 6 / x50\n",
    "}\n",
    "\n",
    "unit_coef = {}     \n",
    "\n",
    "golden12 = [\n",
    "    \"site\", \"blast_id\",                  \n",
    "    \"spacing_over_burden\",\n",
    "    \"benchheight_over_burden\",\n",
    "    \"burden_over_diameter\",\n",
    "    \"stemming_over_burden\",\n",
    "    \"powder_factor\",\n",
    "    \"youngs_modulus_gpa\",\n",
    "    \"fragment_median_m\",\n",
    "    \"fragmentation_index\",\n",
    "    \"group\",\n",
    "    \"mesh_area_m2\",                      \n",
    "]\n",
    "\n",
    "# 1. Load\n",
    "print(f\"Reading {INPUT_FILE} (sheet='{SHEET_NAME}')\")\n",
    "df_raw = pd.read_excel(INPUT_FILE, sheet_name=SHEET_NAME)\n",
    "print(\"Original shape :\", df_raw.shape)\n",
    "\n",
    "# 2. Diagnostics \n",
    "print(\"\\n== dtypes ==\")\n",
    "print(df_raw.dtypes)\n",
    "print(\"\\n== descriptive stats (numeric only) ==\")\n",
    "print(df_raw.describe().T)\n",
    "\n",
    "# 3. Rename & unit convert \n",
    "df = df_raw.rename(columns=column_map, errors=\"ignore\")\n",
    "for col, coef in unit_coef.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col] * coef\n",
    "\n",
    "# 3-B.  derive B, S, fragment_median from ssB / ss50 \n",
    "# (1) derive burden & spacing  (ssB = 6 / B)\n",
    "if {\"specific_surface_burden\", \"spacing_over_burden\"}.issubset(df.columns):\n",
    "    mask = df[\"specific_surface_burden\"].notna() & df[\"spacing_over_burden\"].notna()\n",
    "    if mask.any():\n",
    "        B = 6.0 / df.loc[mask, \"specific_surface_burden\"]     # B = 6 / ssB\n",
    "        r = df.loc[mask, \"spacing_over_burden\"]               # S/B\n",
    "        df.loc[mask, \"burden_m\"]  = B\n",
    "        df.loc[mask, \"spacing_m\"] = r * B                     # S = (S/B)·B\n",
    "\n",
    "# (2) derive fragment_median_m if missing and ss50 present\n",
    "if \"fragment_median_m\" not in df.columns and \"specific_surface_x50\" in df.columns:\n",
    "    df[\"fragment_median_m\"] = 6.0 / df[\"specific_surface_x50\"]\n",
    "\n",
    "# 4. Save raw & clean \n",
    "df_raw.to_excel(RAW_OUT, index=False)\n",
    "print(f\"Raw Excel saved: {RAW_OUT}\")\n",
    "\n",
    "# guarantee Golden-12 columns\n",
    "for col in golden12:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "df_clean = df[golden12]\n",
    "df_clean.to_excel(CLEAN_OUT, index=False)\n",
    "print(f\"Clean Excel saved: {CLEAN_OUT}\")\n",
    "\n",
    "# 5. Markdown report\n",
    "missing_rate = df_clean.isna().mean().rename(\"missing_ratio\")\n",
    "report_tbl   = pd.concat([df_clean.describe(include=\"all\").T, missing_rate], axis=1)\n",
    "\n",
    "md_lines = [\n",
    "    \"# hudaverdi 2010 - cleaning report\",\n",
    "    \"\",\n",
    "    f\"* source file : `{INPUT_FILE}`\",\n",
    "    f\"* original shape : {df_raw.shape}\",\n",
    "    f\"* clean shape    : {df_clean.shape}\",\n",
    "    \"\",\n",
    "    \"## Missing-rate & descriptive stats (Golden-12)\",\n",
    "    report_tbl.to_markdown(),\n",
    "    \"\",\n",
    "]\n",
    "REPORT_MD.write_text(\"\\n\".join(md_lines), encoding=\"utf-8\")\n",
    "print(f\"Markdown report written -> {REPORT_MD}\")\n",
    "\n",
    "print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f96e93",
   "metadata": {},
   "source": [
    "## 4. hudaverdi_2010_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d501572c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/mult_var_blast.xlsx (sheet='hudaverdi_2010_full')\n",
      "Original shape : (110, 11)\n",
      "\n",
      "== dtypes ==\n",
      "Blast No.       int64\n",
      "Blast ID.      object\n",
      "S/B           float64\n",
      "H/B           float64\n",
      "B/D           float64\n",
      "T/B           float64\n",
      "PF (kg/m3)    float64\n",
      "XB (m)        float64\n",
      "E (GPa)       float64\n",
      "X50 (m)       float64\n",
      "FI            float64\n",
      "dtype: object\n",
      "\n",
      "== descriptive stats (numeric only) ==\n",
      "            count       mean        std    min      25%        50%        75%  \\\n",
      "Blast No.   110.0  55.500000  31.898276   1.00  28.2500  55.500000  82.750000   \n",
      "S/B         110.0   1.185000   0.114241   1.00   1.1300   1.200000   1.247500   \n",
      "H/B         110.0   3.338455   1.602141   1.33   2.0700   2.815000   4.687500   \n",
      "B/D         110.0  27.414909   4.942791  17.98  24.7200  27.270000  30.300000   \n",
      "T/B         110.0   1.258455   0.672038   0.50   0.8300   1.110000   1.400000   \n",
      "PF (kg/m3)  110.0   0.539273   0.238742   0.22   0.3525   0.480000   0.682500   \n",
      "XB (m)      110.0   1.092455   0.529778   0.02   0.6925   1.030000   1.522500   \n",
      "E (GPa)     110.0  29.165455  17.824318   9.57  15.0000  16.900000  45.000000   \n",
      "X50 (m)     110.0   0.299455   0.184400   0.02   0.1700   0.230000   0.395000   \n",
      "FI          110.0   4.395850   2.942497   1.00   2.5000   3.297059   5.888736   \n",
      "\n",
      "                   max  \n",
      "Blast No.   110.000000  \n",
      "S/B           1.750000  \n",
      "H/B           6.820000  \n",
      "B/D          39.470000  \n",
      "T/B           4.670000  \n",
      "PF (kg/m3)    1.260000  \n",
      "XB (m)        2.350000  \n",
      "E (GPa)      60.000000  \n",
      "X50 (m)       0.960000  \n",
      "FI           15.666667  \n",
      "Raw Excel saved: hudaverdi_2010_full_raw.xlsx\n",
      "Clean Excel saved: hudaverdi_2010_full_clean.xlsx\n",
      "Markdown report written -> hudaverdi_2010_full_report.md\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Clean & unify the 'hudaverdi_2010_full' sheet from mult_var_blast.xlsx\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Parameters \n",
    "INPUT_FILE = Path(\"data/mult_var_blast.xlsx\")\n",
    "SHEET_NAME = \"hudaverdi_2010_full\"\n",
    "\n",
    "RAW_OUT   = Path(\"hudaverdi_2010_full_raw.xlsx\")\n",
    "CLEAN_OUT = Path(\"hudaverdi_2010_full_clean.xlsx\")\n",
    "REPORT_MD = Path(\"hudaverdi_2010_full_report.md\")\n",
    "\n",
    "# Column mapping: original -> unified \n",
    "column_map = {\n",
    "    \"Blast No.\"     : \"blast_id\",              \n",
    "    \"Blast ID.\"     : \"blast_code\",            \n",
    "    \"S/B\"           : \"spacing_over_burden\",\n",
    "    \"H/B\"           : \"benchheight_over_burden\",\n",
    "    \"B/D\"           : \"burden_over_diameter\",\n",
    "    \"T/B\"           : \"stemming_over_burden\",\n",
    "    \"PF (kg/m3)\"    : \"powder_factor\",\n",
    "    \"XB (m)\"        : \"x_burden_pred_m\",\n",
    "    \"E (GPa)\"       : \"youngs_modulus_gpa\",\n",
    "    \"X50 (m)\"       : \"fragment_median_m\",\n",
    "    \"FI\"            : \"fragmentation_index\",\n",
    "    # No group / ssB / ss50\n",
    "}\n",
    "\n",
    "unit_coef = {}     \n",
    "\n",
    "golden12 = [\n",
    "    \"site\", \"blast_id\",                  \n",
    "    \"spacing_over_burden\",\n",
    "    \"benchheight_over_burden\",\n",
    "    \"burden_over_diameter\",\n",
    "    \"stemming_over_burden\",\n",
    "    \"powder_factor\",\n",
    "    \"youngs_modulus_gpa\",\n",
    "    \"fragment_median_m\",\n",
    "    \"fragmentation_index\",\n",
    "    \"group\",\n",
    "    \"mesh_area_m2\",                      \n",
    "]\n",
    "\n",
    "# 1. Load \n",
    "print(f\"Reading {INPUT_FILE} (sheet='{SHEET_NAME}')\")\n",
    "df_raw = pd.read_excel(INPUT_FILE, sheet_name=SHEET_NAME)\n",
    "print(\"Original shape :\", df_raw.shape)\n",
    "\n",
    "# 2. Diagnostics\n",
    "print(\"\\n== dtypes ==\")\n",
    "print(df_raw.dtypes)\n",
    "print(\"\\n== descriptive stats (numeric only) ==\")\n",
    "print(df_raw.describe().T)\n",
    "\n",
    "# 3. Rename & unit convert \n",
    "df = df_raw.rename(columns=column_map, errors=\"ignore\")\n",
    "for col, coef in unit_coef.items():\n",
    "    if col in df.columns:\n",
    "        df[col] *= coef\n",
    "\n",
    "# 4. Save raw & clean \n",
    "df_raw.to_excel(RAW_OUT, index=False)\n",
    "print(f\"Raw Excel saved: {RAW_OUT}\")\n",
    "\n",
    "# derive text group from FI \n",
    "if \"fragmentation_index\" in df.columns:\n",
    "    bins   = [-float(\"inf\"), 4, 8, float(\"inf\")]\n",
    "    labels = [\"FI<4\", \"4<=FI<=8\", \"FI>8\"]\n",
    "    df[\"group\"] = pd.cut(\n",
    "        df[\"fragmentation_index\"],\n",
    "        bins=bins,\n",
    "        labels=labels\n",
    "    )\n",
    "\n",
    "# guarantee Golden-12 columns\n",
    "for col in golden12:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "\n",
    "df_clean = df[golden12]\n",
    "df_clean.to_excel(CLEAN_OUT, index=False)\n",
    "print(f\"Clean Excel saved: {CLEAN_OUT}\")\n",
    "\n",
    "# 5. Markdown report \n",
    "missing_rate = df_clean.isna().mean().rename(\"missing_ratio\")\n",
    "report_tbl   = pd.concat([df_clean.describe(include=\"all\").T, missing_rate], axis=1)\n",
    "\n",
    "md_lines = [\n",
    "    \"# hudaverdi 2010 full - cleaning report\",\n",
    "    \"\",\n",
    "    f\"* source file : `{INPUT_FILE}`\",\n",
    "    f\"* original shape : {df_raw.shape}\",\n",
    "    f\"* clean shape    : {df_clean.shape}\",\n",
    "    \"\",\n",
    "    \"## Missing-rate & descriptive stats (Golden-12)\",\n",
    "    report_tbl.to_markdown(),\n",
    "    \"\",\n",
    "]\n",
    "REPORT_MD.write_text(\"\\n\".join(md_lines), encoding=\"utf-8\")\n",
    "print(f\"Markdown report written -> {REPORT_MD}\")\n",
    "\n",
    "print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc9d861",
   "metadata": {},
   "source": [
    "## 5. hudaverdi_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23ad9ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/mult_var_blast.xlsx (sheet='hudaverdi_2012')\n",
      "Original shape : (62, 16)\n",
      "\n",
      "== dtypes ==\n",
      "blast           object\n",
      "b[m]           float64\n",
      "S/B            float64\n",
      "H/B            float64\n",
      "B/D            float64\n",
      "T/B            float64\n",
      "PF[kg/m³]      float64\n",
      "xB[m]          float64\n",
      "E[Gpa]         float64\n",
      "x50[m]         float64\n",
      "FI             float64\n",
      "group            int64\n",
      "group_type      object\n",
      "Unnamed: 13    float64\n",
      "variable        object\n",
      "OBS            float64\n",
      "dtype: object\n",
      "\n",
      "== descriptive stats (numeric only) ==\n",
      "             count       mean       std    min      25%    50%      75%    max\n",
      "b[m]          62.0   3.249194  2.034850   1.60   2.0000   2.50   2.9250   9.00\n",
      "S/B           62.0   1.197903  0.133970   1.00   1.1400   1.20   1.2500   1.75\n",
      "H/B           62.0   3.762258  1.347131   1.67   2.5000   3.50   4.7500   6.82\n",
      "B/D           62.0  26.680806  5.525936  17.98  22.2825  28.09  32.2525  39.47\n",
      "T/B           62.0   1.178710  0.385769   0.50   0.8300   1.20   1.5450   1.75\n",
      "PF[kg/m³]     62.0   0.598710  0.252408   0.26   0.4200   0.53   0.7175   1.26\n",
      "xB[m]         62.0   1.003065  0.538817   0.02   0.5600   1.00   1.5000   2.35\n",
      "E[Gpa]        62.0  17.220645  7.454213   9.57  13.2500  16.90  16.9000  32.00\n",
      "x50[m]        62.0   0.204839  0.114215   0.02   0.1500   0.17   0.2200   0.76\n",
      "FI            62.0   5.409677  3.407786   1.00   2.6700   5.11   7.2150  15.67\n",
      "group         62.0   1.822581  0.779327   1.00   1.0000   2.00   2.0000   3.00\n",
      "Unnamed: 13    0.0        NaN       NaN    NaN      NaN    NaN      NaN    NaN\n",
      "OBS            0.0        NaN       NaN    NaN      NaN    NaN      NaN    NaN\n",
      "Raw Excel saved: hudaverdi_2012_raw.xlsx\n",
      "Clean Excel saved: hudaverdi_2012_clean.xlsx\n",
      "Markdown report written -> hudaverdi_2012_report.md\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Clean & unify the 'hudaverdi_2012' sheet from mult_var_blast.xlsx\n",
    "\"\"\"\n",
    "\n",
    "# Parameters─\n",
    "INPUT_FILE = Path(\"data/mult_var_blast.xlsx\")\n",
    "SHEET_NAME = \"hudaverdi_2012\"\n",
    "\n",
    "RAW_OUT   = Path(\"hudaverdi_2012_raw.xlsx\")\n",
    "CLEAN_OUT = Path(\"hudaverdi_2012_clean.xlsx\")\n",
    "REPORT_MD = Path(\"hudaverdi_2012_report.md\")\n",
    "\n",
    "# Column mapping: original -> unified\n",
    "column_map = {\n",
    "    \"blast\"        : \"blast_id\",             \n",
    "    \"b[m]\"         : \"burden_m\",\n",
    "    \"S/B\"          : \"spacing_over_burden\",\n",
    "    \"H/B\"          : \"benchheight_over_burden\",\n",
    "    \"B/D\"          : \"burden_over_diameter\",\n",
    "    \"T/B\"          : \"stemming_over_burden\",\n",
    "    \"PF[kg/m³]\"    : \"powder_factor\",\n",
    "    \"xB[m]\"        : \"x_burden_pred_m\",\n",
    "    \"E[Gpa]\"       : \"youngs_modulus_gpa\",\n",
    "    \"x50[m]\"       : \"fragment_median_m\",\n",
    "    \"FI\"           : \"fragmentation_index\",\n",
    "    \"group\"        : \"group_numeric\",         \n",
    "    \"group_type\"   : \"group_type\",            \n",
    "}\n",
    "\n",
    "unit_coef = {}  \n",
    "\n",
    "golden12 = [\n",
    "    \"site\", \"blast_id\",\n",
    "    \"spacing_over_burden\",\n",
    "    \"benchheight_over_burden\",\n",
    "    \"burden_over_diameter\",\n",
    "    \"stemming_over_burden\",\n",
    "    \"powder_factor\",\n",
    "    \"youngs_modulus_gpa\",\n",
    "    \"fragment_median_m\",\n",
    "    \"fragmentation_index\",\n",
    "    \"group\",              \n",
    "    \"mesh_area_m2\",\n",
    "]\n",
    "\n",
    "# 1. Load \n",
    "print(f\"Reading {INPUT_FILE} (sheet='{SHEET_NAME}')\")\n",
    "df_raw = pd.read_excel(INPUT_FILE, sheet_name=SHEET_NAME)\n",
    "print(\"Original shape :\", df_raw.shape)\n",
    "\n",
    "# 2. Diagnostics\n",
    "print(\"\\n== dtypes ==\")\n",
    "print(df_raw.dtypes)\n",
    "print(\"\\n== descriptive stats (numeric only) ==\")\n",
    "print(df_raw.describe().T)\n",
    "\n",
    "# 3. Rename & unit convert\n",
    "df = df_raw.rename(columns=column_map, errors=\"ignore\")\n",
    "for col, coef in unit_coef.items():\n",
    "    if col in df.columns:\n",
    "        df[col] *= coef\n",
    "\n",
    "# 3-A. Unify group to text label\n",
    "if \"group_type\" in df.columns:\n",
    "\n",
    "    df[\"group\"] = df[\"group_type\"]\n",
    "elif \"fragmentation_index\" in df.columns:\n",
    "    # basing on FI\n",
    "    bins   = [-float(\"inf\"), 4, 8, float(\"inf\")]\n",
    "    labels = [\"FI<4\", \"4<=FI<=8\", \"FI>8\"]\n",
    "    df[\"group\"] = pd.cut(df[\"fragmentation_index\"], bins=bins, labels=labels)\n",
    "\n",
    "# 4. Save raw & clean \n",
    "df_raw.to_excel(RAW_OUT, index=False)\n",
    "print(f\"Raw Excel saved: {RAW_OUT}\")\n",
    "\n",
    "for col in golden12:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "df_clean = df[golden12]\n",
    "df_clean.to_excel(CLEAN_OUT, index=False)\n",
    "print(f\"Clean Excel saved: {CLEAN_OUT}\")\n",
    "\n",
    "# 5. Markdown report\n",
    "missing_rate = df_clean.isna().mean().rename(\"missing_ratio\")\n",
    "report_tbl   = pd.concat([df_clean.describe(include=\"all\").T, missing_rate], axis=1)\n",
    "\n",
    "md_lines = [\n",
    "    \"# hudaverdi 2012 - cleaning report\",\n",
    "    \"\",\n",
    "    f\"* source file : `{INPUT_FILE}`\",\n",
    "    f\"* original shape : {df_raw.shape}\",\n",
    "    f\"* clean shape    : {df_clean.shape}\",\n",
    "    \"\",\n",
    "    \"## Missing-rate & descriptive stats (Golden-12)\",\n",
    "    report_tbl.to_markdown(),\n",
    "    \"\",\n",
    "]\n",
    "REPORT_MD.write_text(\"\\n\".join(md_lines), encoding=\"utf-8\")\n",
    "print(f\"Markdown report written -> {REPORT_MD}\")\n",
    "\n",
    "print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89d293",
   "metadata": {},
   "source": [
    "## 6. hudaverdi_2012_vib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5829798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/mult_var_blast.xlsx (sheet='hudaverdi_2012_vib')\n",
      "Original shape : (88, 21)\n",
      "\n",
      "== dtypes ==\n",
      "blast             int64\n",
      "S/B             float64\n",
      "H/B             float64\n",
      "B/D             float64\n",
      "T/B             float64\n",
      "U/B             float64\n",
      "PF[kg/m³]       float64\n",
      "Q/delay[kg]     float64\n",
      "d[m]              int64\n",
      "Sd[kg/Q^0.5]    float64\n",
      "PPV[mm/s]       float64\n",
      "group             int64\n",
      "Unnamed: 12     float64\n",
      "variable         object\n",
      "OBS             float64\n",
      "Unnamed: 15     float64\n",
      "variable.1       object\n",
      "min             float64\n",
      "max             float64\n",
      "mean            float64\n",
      "std_dev         float64\n",
      "dtype: object\n",
      "\n",
      "== descriptive stats (numeric only) ==\n",
      "              count        mean        std     min        25%       50%  \\\n",
      "blast          88.0   44.500000  25.547342   1.000   22.75000   44.5000   \n",
      "S/B            88.0    1.188409   0.058700   1.000    1.14000    1.2000   \n",
      "H/B            88.0    3.215568   0.487624   2.400    2.89000    3.1800   \n",
      "B/D            88.0   25.178295   2.582654  20.220   22.47000   24.7200   \n",
      "T/B            88.0    1.164432   0.155178   0.800    1.03000    1.2000   \n",
      "U/B            88.0    0.226250   0.022607   0.180    0.20000    0.2300   \n",
      "PF[kg/m³]      88.0    0.644318   0.122463   0.470    0.53750    0.6500   \n",
      "Q/delay[kg]    88.0  124.500000  34.882433  55.500  103.40000  121.0500   \n",
      "d[m]           88.0  145.511364  50.155160  55.000  110.00000  145.0000   \n",
      "Sd[kg/Q^0.5]   88.0   13.198750   4.419121   4.350   10.46500   12.7800   \n",
      "PPV[mm/s]      88.0   12.778295   7.961041   1.800    6.92750   11.5000   \n",
      "group          88.0    1.511364   0.502735   1.000    1.00000    2.0000   \n",
      "Unnamed: 12     0.0         NaN        NaN     NaN        NaN       NaN   \n",
      "OBS             0.0         NaN        NaN     NaN        NaN       NaN   \n",
      "Unnamed: 15     0.0         NaN        NaN     NaN        NaN       NaN   \n",
      "min             6.0    4.178333   7.896213   0.180    0.55250    0.9000   \n",
      "max             6.0    6.128333  10.852836   0.300    1.06250    1.4750   \n",
      "mean            6.0    5.270000   9.808033   0.230    0.77000    1.1750   \n",
      "std_dev         6.0    0.571667   0.999213   0.023    0.07475    0.1385   \n",
      "\n",
      "                    75%      max  \n",
      "blast          66.25000   88.000  \n",
      "S/B             1.25000    1.280  \n",
      "H/B             3.50000    4.440  \n",
      "B/D            28.09000   28.090  \n",
      "T/B             1.25000    1.670  \n",
      "U/B             0.24000    0.300  \n",
      "PF[kg/m³]       0.74000    0.990  \n",
      "Q/delay[kg]   142.70000  227.300  \n",
      "d[m]          180.00000  245.000  \n",
      "Sd[kg/Q^0.5]   15.60750   26.660  \n",
      "PPV[mm/s]      17.00000   36.200  \n",
      "group           2.00000    2.000  \n",
      "Unnamed: 12         NaN      NaN  \n",
      "OBS                 NaN      NaN  \n",
      "Unnamed: 15         NaN      NaN  \n",
      "min             2.05000   20.220  \n",
      "max             3.74750   28.090  \n",
      "mean            2.71250   25.180  \n",
      "std_dev         0.40475    2.583  \n",
      " Raw Excel saved: hudaverdi_2012_vib_raw.xlsx\n",
      " Clean Excel saved: hudaverdi_2012_vib_clean.xlsx\n",
      "Markdown report written -> hudaverdi_2012_vib_report.md\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Clean & unify the 'hudaverdi_2012_vib' sheet from mult_var_blast.xlsx\n",
    "\"\"\"\n",
    "\n",
    "# Parameters\n",
    "INPUT_FILE = Path(\"data/mult_var_blast.xlsx\")\n",
    "SHEET_NAME = \"hudaverdi_2012_vib\"\n",
    "\n",
    "RAW_OUT   = Path(\"hudaverdi_2012_vib_raw.xlsx\")\n",
    "CLEAN_OUT = Path(\"hudaverdi_2012_vib_clean.xlsx\")\n",
    "REPORT_MD = Path(\"hudaverdi_2012_vib_report.md\")\n",
    "\n",
    "# Column mapping: original -> unified\n",
    "column_map = {\n",
    "    \"blast\"         : \"blast_id\",\n",
    "    \"S/B\"           : \"spacing_over_burden\",\n",
    "    \"H/B\"           : \"benchheight_over_burden\",\n",
    "    \"B/D\"           : \"burden_over_diameter\",\n",
    "    \"T/B\"           : \"stemming_over_burden\",\n",
    "    \"U/B\"           : \"subdrill_over_burden\",\n",
    "    \"PF[kg/m³]\"     : \"powder_factor\",\n",
    "    \"Q/delay[kg]\"   : \"charge_per_delay_kg\",\n",
    "    \"d[m]\"          : \"distance_m\",\n",
    "    \"Sd[kg/Q^0.5]\"  : \"scaled_distance\",\n",
    "    \"PPV[mm/s]\"     : \"ppv_mms\",\n",
    "    \"group\"         : \"group_numeric\",      \n",
    "}\n",
    "\n",
    "unit_coef = {}  \n",
    "\n",
    "golden12 = [\n",
    "    \"site\", \"blast_id\",\n",
    "    \"spacing_over_burden\",\n",
    "    \"benchheight_over_burden\",\n",
    "    \"burden_over_diameter\",\n",
    "    \"stemming_over_burden\",\n",
    "    \"powder_factor\",\n",
    "    \"youngs_modulus_gpa\",      \n",
    "    \"fragment_median_m\",       \n",
    "    \"fragmentation_index\",     \n",
    "    \"group\",                   \n",
    "    \"mesh_area_m2\",            \n",
    "]\n",
    "\n",
    "# 1. Load\n",
    "print(f\"Reading {INPUT_FILE} (sheet='{SHEET_NAME}')\")\n",
    "df_raw = pd.read_excel(INPUT_FILE, sheet_name=SHEET_NAME)\n",
    "print(\"Original shape :\", df_raw.shape)\n",
    "\n",
    "# 2. Diagnostics \n",
    "print(\"\\n== dtypes ==\")\n",
    "print(df_raw.dtypes)\n",
    "print(\"\\n== descriptive stats (numeric only) ==\")\n",
    "print(df_raw.describe().T)\n",
    "\n",
    "# 3. Rename & unit convert \n",
    "df = df_raw.rename(columns=column_map, errors=\"ignore\")\n",
    "for col, coef in unit_coef.items():\n",
    "    if col in df.columns:\n",
    "        df[col] *= coef\n",
    "\n",
    "# 3-A. numeric group -> text label\n",
    "if \"group_numeric\" in df.columns:\n",
    "    df[\"group\"] = df[\"group_numeric\"].map({1: \"FI<4\", 2: \"4<=FI<=8\", 3: \"FI>8\"}).astype(\"string\")\n",
    "\n",
    "\n",
    "# 4. Save raw & clean\n",
    "df_raw.to_excel(RAW_OUT, index=False)\n",
    "print(f\" Raw Excel saved: {RAW_OUT}\")\n",
    "\n",
    "# Golden-12\n",
    "for col in golden12:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "df_clean = df[golden12]        \n",
    "\n",
    "df_vib   = df[[\"blast_id\", \"charge_per_delay_kg\", \"distance_m\",\n",
    "               \"scaled_distance\", \"ppv_mms\"]]\n",
    "\n",
    "df_clean.to_excel(CLEAN_OUT, index=False)\n",
    "print(f\" Clean Excel saved: {CLEAN_OUT}\")\n",
    "\n",
    "# 5. Markdown report\n",
    "missing_rate = df_clean.isna().mean().rename(\"missing_ratio\")\n",
    "report_tbl   = pd.concat([df_clean.describe(include=\"all\").T, missing_rate],\n",
    "                         axis=1)\n",
    "\n",
    "md_lines = [\n",
    "    \"# hudaverdi 2012 vib - cleaning report\",\n",
    "    \"\",\n",
    "    f\"* source file : `{INPUT_FILE}`\",\n",
    "    f\"* original shape : {df_raw.shape}\",\n",
    "    f\"* clean shape    : {df_clean.shape}\",\n",
    "    \"\",\n",
    "    \"## Missing-rate & descriptive stats (Golden-12)\",\n",
    "    report_tbl.to_markdown(),\n",
    "    \"\",\n",
    "    \"## Extra vibration columns kept (not in Golden-12)\",\n",
    "    \"`charge_per_delay_kg`, `distance_m`, `scaled_distance`, `ppv_mms`\",\n",
    "]\n",
    "REPORT_MD.write_text(\"\\n\".join(md_lines), encoding=\"utf-8\")\n",
    "print(f\"Markdown report written -> {REPORT_MD}\")\n",
    "\n",
    "print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3d789",
   "metadata": {},
   "source": [
    "## 7. trivedi_2014_flyrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fcc94b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/mult_var_blast.xlsx (sheet='trivedi_2014_flyrock')\n",
      "Original shape : (30, 19)\n",
      " Raw Excel saved: trivedi_2014_flyrock_raw.xlsx\n",
      " Clean Excel saved: trivedi_2014_flyrock_clean.xlsx\n",
      "Markdown report written -> trivedi_2014_flyrock_report.md\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Clean & unify the 'trivedi_2014_flyrock' sheet from mult_var_blast.xlsx\n",
    "\"\"\"\n",
    "\n",
    "# Parameters \n",
    "INPUT_FILE = Path(\"data/mult_var_blast.xlsx\")\n",
    "SHEET_NAME = \"trivedi_2014_flyrock\"\n",
    "RAW_OUT   = Path(\"trivedi_2014_flyrock_raw.xlsx\")\n",
    "CLEAN_OUT = Path(\"trivedi_2014_flyrock_clean.xlsx\")\n",
    "REPORT_MD = Path(\"trivedi_2014_flyrock_report.md\")\n",
    "\n",
    "# Column mapping: original -> unified\n",
    "column_map = {\n",
    "    \"Blast No.\"       : \"blast_id\",\n",
    "    \"Name of the mine\": \"site\",\n",
    "    \"d(mm)\"           : \"hole_diameter_mm\",\n",
    "    \"Q(kg)\"           : \"charge_per_hole_kg\",\n",
    "    \"ql(kg/m)\"        : \"linear_charge_density\",\n",
    "    \"lb(m)\"           : \"hole_depth_m\",\n",
    "    \"B(m)\"            : \"burden_m\",\n",
    "    \"Sb(m)\"           : \"spacing_m\",\n",
    "    \"ls(m)\"           : \"stemming_m\",\n",
    "    \"q(kg/t)\"         : \"specific_charge_kgt\",\n",
    "    \"σc(MPa)\"         : \"ucs_mpa\",\n",
    "    \"RQD(%)\"          : \"rqd_pct\",\n",
    "    \"v0(m/s)\"         : \"flyrock_velocity_ms\",\n",
    "    \"θ0(°)\"           : \"flyrock_angle_deg\",\n",
    "    \"Rf(m)\"           : \"flyrock_distance_m\",\n",
    "}\n",
    "\n",
    "unit_coef = {\n",
    "    \"hole_diameter_mm\": 0.001,        # mm -> m\n",
    "}\n",
    "\n",
    "# Golden-12 \n",
    "golden12 = [\n",
    "    \"site\", \"blast_id\",\n",
    "    \"spacing_over_burden\",\n",
    "    \"benchheight_over_burden\",        # None -> NaN\n",
    "    \"burden_over_diameter\",\n",
    "    \"stemming_over_burden\",\n",
    "    \"powder_factor\",                  # None -> NaN\n",
    "    \"youngs_modulus_gpa\",             # None -> NaN\n",
    "    \"fragment_median_m\",              # None -> NaN\n",
    "    \"fragmentation_index\",            # None -> NaN\n",
    "    \"group\",                          # None -> NaN\n",
    "    \"mesh_area_m2\",\n",
    "]\n",
    "\n",
    "# 1. Load\n",
    "print(f\"Reading {INPUT_FILE} (sheet='{SHEET_NAME}')\")\n",
    "df_raw = pd.read_excel(INPUT_FILE, sheet_name=SHEET_NAME)\n",
    "print(\"Original shape :\", df_raw.shape)\n",
    "\n",
    "# 2. Diagnostics\n",
    "df = df_raw.rename(columns=column_map, errors=\"ignore\")\n",
    "for col, coef in unit_coef.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col] * coef\n",
    "\n",
    "# 3. Rename & unit convert\n",
    "# 3-A mesh area\n",
    "if {\"spacing_m\", \"burden_m\"}.issubset(df.columns):\n",
    "    df[\"mesh_area_m2\"] = df[\"spacing_m\"] * df[\"burden_m\"]\n",
    "    df[\"spacing_over_burden\"] = df[\"spacing_m\"] / df[\"burden_m\"]\n",
    "\n",
    "# 3-B burden_over_diameter\n",
    "if {\"burden_m\", \"hole_diameter_mm\"}.issubset(df.columns):\n",
    "    df[\"burden_over_diameter\"] = df[\"burden_m\"] / df[\"hole_diameter_mm\"]\n",
    "\n",
    "# 3-C stemming_over_burden\n",
    "if {\"stemming_m\", \"burden_m\"}.issubset(df.columns):\n",
    "    df[\"stemming_over_burden\"] = df[\"stemming_m\"] / df[\"burden_m\"]\n",
    "\n",
    "# 3-D fill other Golden-12 columns with NA\n",
    "for col in golden12:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "\n",
    "# 4. Save raw & clean\n",
    "df_raw.to_excel(RAW_OUT, index=False)\n",
    "print(f\" Raw Excel saved: {RAW_OUT}\")\n",
    "\n",
    "df_clean = df[golden12]\n",
    "df_clean.to_excel(CLEAN_OUT, index=False)\n",
    "print(f\" Clean Excel saved: {CLEAN_OUT}\")\n",
    "\n",
    "# 5. Markdown report\n",
    "missing_rate = df_clean.isna().mean().rename(\"missing_ratio\")\n",
    "report_tbl   = pd.concat([df_clean.describe(include=\"all\").T, missing_rate], axis=1)\n",
    "\n",
    "md_lines = [\n",
    "    \"# trivedi 2014 flyrock  cleaning report\",\n",
    "    \"\",\n",
    "    f\"* source file : `{INPUT_FILE}`\",\n",
    "    f\"* original shape : {df_raw.shape}\",\n",
    "    f\"* clean shape    : {df_clean.shape}\",\n",
    "    \"\",\n",
    "    \"## Missing-rate & descriptive stats (Golden-12)\",\n",
    "    report_tbl.to_markdown(),\n",
    "    \"\",\n",
    "    \"## Extra fly-rock features kept\",\n",
    "    \"`charge_per_hole_kg`, `linear_charge_density`, `hole_depth_m`, \"\n",
    "    \"`specific_charge_kgt`, `ucs_mpa`, `rqd_pct`, \"\n",
    "    \"`flyrock_velocity_ms`, `flyrock_angle_deg`, `flyrock_distance_m`\",\n",
    "]\n",
    "REPORT_MD.write_text(\"\\n\".join(md_lines), encoding=\"utf-8\")\n",
    "print(f\"Markdown report written -> {REPORT_MD}\")\n",
    "\n",
    "print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00364d1b",
   "metadata": {},
   "source": [
    "## 8. sharma_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c50ba210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data/mult_var_blast.xlsx (sheet='sharma_2017')\n",
      "Original shape : (76, 50)\n",
      " Raw Excel saved: sharma_2017_raw.xlsx\n",
      "Clean Excel saved: sharma_2017_clean.xlsx\n",
      "Markdown report written -> sharma_2017_report.md\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Clean & unify the 'sharma_2017' sheet from mult_var_blast.xlsx\n",
    "\"\"\"\n",
    "\n",
    "# Parameters\n",
    "INPUT_FILE = Path(\"data/mult_var_blast.xlsx\")\n",
    "SHEET_NAME = \"sharma_2017\"\n",
    "RAW_OUT   = Path(\"sharma_2017_raw.xlsx\")\n",
    "CLEAN_OUT = Path(\"sharma_2017_clean.xlsx\")\n",
    "REPORT_MD = Path(\"sharma_2017_report.md\")\n",
    "\n",
    "# Column mapping: original -> unified\n",
    "column_map = {\n",
    "    \"blast_ID\" : \"blast_id\",\n",
    "    # Geometric parameters\n",
    "    \"D\" : \"hole_diameter_m\",\n",
    "    \"H\" : \"bench_height_m\",\n",
    "    \"J\" : \"subgrade_drilling_m\",\n",
    "    \"S\" : \"spacing_m\",\n",
    "    \"B\" : \"burden_m\",\n",
    "    \"T\" : \"stemming_m\",\n",
    "    \"L\" : \"length_m\",\n",
    "    \"W\" : \"width_m\",\n",
    "    # ratio (given)\n",
    "    \"S/B\" : \"spacing_over_burden\",\n",
    "    \"T/B\" : \"stemming_over_burden\",\n",
    "    \"H/B\" : \"benchheight_over_burden\",\n",
    "    \"J/B\" : \"subgrade_over_burden\",\n",
    "    \"B/D\" : \"burden_over_diameter\",\n",
    "    \"L/W\" : \"length_over_width\",\n",
    "    # Blasting parameters\n",
    "    \"NH\" : \"num_holes\",\n",
    "    \"Qe\" : \"total_explosive_t\",\n",
    "    \"De\" : \"linear_explosive_density\",\n",
    "    \"PF\" : \"powder_factor_m3kg\",   # m3/kg\n",
    "    # Rock & results\n",
    "    \"UCS\" : \"ucs_mpa\",\n",
    "    \"MFS\" : \"mean_fragment_size_m\",\n",
    "    \"dataset\" : \"dataset_id\",\n",
    "}\n",
    "\n",
    "unit_coef = {\n",
    "\n",
    "}\n",
    "\n",
    "golden12 = [\n",
    "    \"site\", \"blast_id\",\n",
    "    \"spacing_over_burden\",\n",
    "    \"benchheight_over_burden\",\n",
    "    \"burden_over_diameter\",\n",
    "    \"stemming_over_burden\",\n",
    "    \"powder_factor\",\n",
    "    \"youngs_modulus_gpa\",\n",
    "    \"fragment_median_m\",\n",
    "    \"fragmentation_index\",\n",
    "    \"group\",\n",
    "    \"mesh_area_m2\",\n",
    "]\n",
    "\n",
    "# 1. Load\n",
    "print(f\"Reading {INPUT_FILE} (sheet='{SHEET_NAME}')\")\n",
    "df_raw = pd.read_excel(INPUT_FILE, sheet_name=SHEET_NAME)\n",
    "print(\"Original shape :\", df_raw.shape)\n",
    "\n",
    "# 2. Diagnostics\n",
    "df = df_raw.rename(columns=column_map, errors=\"ignore\")\n",
    "\n",
    "# 3. Rename & unit convert\n",
    "# powder factor m3/kg -> kg/m3\n",
    "if \"powder_factor_m3kg\" in df.columns:\n",
    "    pf = df[\"powder_factor_m3kg\"]\n",
    "    df[\"powder_factor\"] = np.where(pf > 0, 1.0 / pf, pd.NA)\n",
    "\n",
    "# 4. Supplement columns\n",
    "# 4-A mesh area\n",
    "if {\"spacing_m\", \"burden_m\"}.issubset(df.columns):\n",
    "    df[\"mesh_area_m2\"] = df[\"spacing_m\"] * df[\"burden_m\"]\n",
    "\n",
    "# 4-B fragment_median_m use MFS\n",
    "if \"mean_fragment_size_m\" in df.columns:\n",
    "    df[\"fragment_median_m\"] = df[\"mean_fragment_size_m\"]\n",
    "\n",
    "# 5. Save\n",
    "df_raw.to_excel(RAW_OUT, index=False)\n",
    "print(f\" Raw Excel saved: {RAW_OUT}\")\n",
    "\n",
    "# Golden-12\n",
    "for col in golden12:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "df_clean = df[golden12]\n",
    "df_clean.to_excel(CLEAN_OUT, index=False)\n",
    "print(f\"Clean Excel saved: {CLEAN_OUT}\")\n",
    "\n",
    "# 6. Markdown report\n",
    "missing_rate = df_clean.isna().mean().rename(\"missing_ratio\")\n",
    "report_tbl   = pd.concat([df_clean.describe(include=\"all\").T, missing_rate], axis=1)\n",
    "\n",
    "md_lines = [\n",
    "    \"# sharma 2017 - cleaning report\",\n",
    "    \"\",\n",
    "    f\"* source file : `{INPUT_FILE}`\",\n",
    "    f\"* original shape : {df_raw.shape}\",\n",
    "    f\"* clean shape    : {df_clean.shape}\",\n",
    "    \"\",\n",
    "    \"## Missing-rate & descriptive stats (Golden-12)\",\n",
    "    report_tbl.to_markdown(),\n",
    "    \"\",\n",
    "    \"# Extra columns kept (not in Golden-12)\",\n",
    "    \"`hole_diameter_m`, `bench_height_m`, `subgrade_drilling_m`, `spacing_m`, \"\n",
    "    \"`burden_m`, `stemming_m`, `length_m`, `width_m`, \"\n",
    "    \"`subgrade_over_burden`, `length_over_width`, \"\n",
    "    \"`num_holes`, `total_explosive_t`, `linear_explosive_density`, \"\n",
    "    \"`ucs_mpa`, `dataset_id`\",\n",
    "]\n",
    "REPORT_MD.write_text(\"\\n\".join(md_lines), encoding=\"utf-8\")\n",
    "print(f\"Markdown report written -> {REPORT_MD}\")\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1291be",
   "metadata": {},
   "source": [
    "# Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3283b8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged file: clean_data/fi_pool.xlsx (262 rows, 13 columns)\n",
      "Summary written: clean_data/fi_pool_summary.md\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Merge three FI-oriented clean tables into a single Excel file.\n",
    "This is a light-weight step for data-scarce settings.\n",
    "\"\"\"\n",
    "\n",
    "# Input files (all have the same Golden-12 columns, plus extras)\n",
    "INPUT_FILES = [\n",
    "    Path(\"clean_data/hudaverdi_2010_full_clean.xlsx\"),\n",
    "    Path(\"clean_data/hudaverdi_2012_clean.xlsx\"),\n",
    "    Path(\"clean_data/kulatilake_2010_clean.xlsx\"),\n",
    "]\n",
    "\n",
    "# Output paths\n",
    "OUT_XLSX   = Path(\"clean_data/fi_pool.xlsx\")\n",
    "OUT_REPORT = Path(\"clean_data/fi_pool_summary.md\")\n",
    "\n",
    "# 1. Read each file and tag its source\n",
    "frames = []\n",
    "for fp in INPUT_FILES:\n",
    "    df = pd.read_excel(fp, engine=\"openpyxl\")\n",
    "    df[\"dataset\"] = fp.stem.replace(\"_clean\", \"\")   # e.g., hudaverdi_2012\n",
    "    frames.append(df)\n",
    "\n",
    "# 2. Vertical concatenation (columns auto-aligned, NaN where missing)\n",
    "fi_pool = pd.concat(frames, ignore_index=True, sort=False)\n",
    "\n",
    "# Build a unique row index in case different sets share blast IDs\n",
    "fi_pool[\"uid\"] = fi_pool[\"dataset\"].astype(str) + \"_\" + fi_pool[\"blast_id\"].astype(str)\n",
    "fi_pool = fi_pool.set_index(\"uid\", drop=True)\n",
    "\n",
    "# 3. Save to Excel\n",
    "OUT_XLSX.parent.mkdir(parents=True, exist_ok=True)\n",
    "fi_pool.to_excel(OUT_XLSX, index=True, engine=\"openpyxl\")\n",
    "print(f\"Saved merged file: {OUT_XLSX} ({fi_pool.shape[0]} rows, {fi_pool.shape[1]} columns)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c99f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed dataset saved.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"data/merged_data/fi_pool.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "# 1. Drop the empty column\n",
    "df = df.drop(columns=[\"mesh_area_m2\"], errors=\"ignore\")\n",
    "\n",
    "# 2. Set uid as index\n",
    "df = df.set_index(\"uid\", drop=True)\n",
    "\n",
    "# 3.  drop meta columns\n",
    "df = df.drop(columns=[\"site\", \"blast_id\"])\n",
    "\n",
    "# 4. Save back to Excel\n",
    "df.to_excel(\"data/merged_data/fi_pool.xlsx\", engine=\"openpyxl\")\n",
    "print(\"Trimmed dataset saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0426b0d2",
   "metadata": {},
   "source": [
    "# Ploting and Statistical Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf44592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Missingness saved -> figure/stats_missing_by_source.csv\n",
      "[OK] Summary saved     -> figure/stats_summary_by_source.csv\n",
      "[OK] Figure D1 saved   -> figure/fig_D1_ecdf.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/h5_sbcb90jnd465r4rgty63w0000gp/T/ipykernel_6783/3635503685.py:157: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig2.tight_layout(rect=[0,0,0.9,1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Figure D2 saved   -> figure/fig_D2_corr.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/h5_sbcb90jnd465r4rgty63w0000gp/T/ipykernel_6783/3635503685.py:177: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig3.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Figure D2 saved  -> figure/fig_2_delta_corr.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute stats and generate figures for the FI pool.\n",
    "Inputs:\n",
    "  - data/merged_data/fi_pool.xlsx        \n",
    "Outputs:\n",
    "  - outputs/stats_missing_by_source.csv\n",
    "  - outputs/stats_summary_by_source.csv\n",
    "  - outputs/fig_D1_ecdf.png\n",
    "  - outputs/fig_D2_corr.png\n",
    "  - outputs/fig_D2_delta_corr.png\n",
    "\"\"\"\n",
    "\n",
    "# I/O paths\n",
    "PREF = Path(\"data/merged_data/fi_pool.xlsx\")\n",
    "OUTD = Path(\"figure\"); OUTD.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "if PREF.exists():\n",
    "    df = pd.read_excel(PREF, engine=\"openpyxl\")\n",
    "\n",
    "# make sure index and dataset\n",
    "if \"uid\" in df.columns:\n",
    "    df = df.set_index(\"uid\", drop=True)\n",
    "if \"dataset\" not in df.columns:\n",
    "    raise ValueError(\"`dataset` column is required to group by source.\")\n",
    "\n",
    "# Optionally drop clearly meta columns if present\n",
    "drop_cols = [c for c in [\"site\",\"blast_id\",\"mesh_area_m2\"] if c in df.columns]\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "# Feature lists\n",
    "\n",
    "# core features used in figures\n",
    "feat_core = [\n",
    "    \"fragmentation_index\",        # FI\n",
    "    \"fragment_median_m\",          # X50\n",
    "    \"powder_factor\",              # PF (kg/m^3)\n",
    "    \"benchheight_over_burden\",    # H/B\n",
    "    \"burden_over_diameter\",       # B/D\n",
    "    \"stemming_over_burden\",       # T/B\n",
    "]\n",
    "# optional extras for correlation\n",
    "feat_corr = [f for f in (feat_core + [\n",
    "    \"spacing_over_burden\", \"youngs_modulus_gpa\"\n",
    "]) if f in df.columns]\n",
    "\n",
    "\n",
    "# Missingness & summary stats\n",
    "\n",
    "# missing by feature & source\n",
    "miss = (df.groupby(\"dataset\")[feat_core]\n",
    "          .apply(lambda x: x.isna().mean()*100.0)\n",
    "          .round(1))\n",
    "miss.to_csv(OUTD/\"stats_missing_by_source.csv\")\n",
    "\n",
    "# numeric summary by source\n",
    "def summary_tbl(g):\n",
    "    s = g[feat_core].agg([\"count\",\"mean\",\"std\",\"min\",\"median\",\"max\"]).T\n",
    "    s[\"skew\"] = g[feat_core].skew(numeric_only=True)\n",
    "    return s\n",
    "\n",
    "summ = []\n",
    "for name, g in df.groupby(\"dataset\"):\n",
    "    t = summary_tbl(g)\n",
    "    t.insert(0, \"dataset\", name)\n",
    "    summ.append(t.reset_index().rename(columns={\"index\":\"feature\"}))\n",
    "summ = pd.concat(summ, ignore_index=True)\n",
    "summ.to_csv(OUTD/\"stats_summary_by_source.csv\", index=False)\n",
    "\n",
    "print(f\"[OK] Missingness saved -> {OUTD/'stats_missing_by_source.csv'}\")\n",
    "print(f\"[OK] Summary saved     -> {OUTD/'stats_summary_by_source.csv'}\")\n",
    "\n",
    "\n",
    "# 4) Figure D1: ECDF by source (6 panels in one figure)\n",
    "def ecdf(y):\n",
    "    y = np.asarray(y)\n",
    "    y = y[~np.isnan(y)]\n",
    "    if y.size == 0: \n",
    "        return np.array([]), np.array([])\n",
    "    y_sorted = np.sort(y)\n",
    "    x = y_sorted\n",
    "    F = np.arange(1, y_sorted.size+1) / y_sorted.size\n",
    "    return x, F\n",
    "\n",
    "panels = [f for f in feat_core if f in df.columns]\n",
    "n_pan = len(panels)\n",
    "ncols  = 3\n",
    "nrows  = int(np.ceil(n_pan/ncols))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 3.6*nrows), dpi=200)\n",
    "plt.suptitle(\"Per-source ECDFs for key features\", y=0.995)\n",
    "\n",
    "for i, f in enumerate(panels, 1):\n",
    "    ax = fig.add_subplot(nrows, ncols, i)\n",
    "    for src, g in df.groupby(\"dataset\"):\n",
    "        x, F = ecdf(g[f].values)\n",
    "        if x.size == 0: \n",
    "            continue\n",
    "        # log-like axis for PF / X50 when all positive\n",
    "        if f in [\"fragment_median_m\",\"powder_factor\"] and np.all(x>0):\n",
    "            ax.set_xscale(\"log\")\n",
    "        ax.step(x, F, where=\"post\", label=str(src), alpha=0.9)\n",
    "    ax.set_xlabel(f)\n",
    "    ax.set_ylabel(\"ECDF\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    if i == 1:\n",
    "        ax.legend(loc=\"lower right\", fontsize=8)\n",
    "\n",
    "fig.tight_layout(rect=[0,0,1,0.98])\n",
    "fig.savefig(OUTD/\"fig_D1_ecdf.png\")\n",
    "plt.close(fig)\n",
    "print(f\"[OK] Figure D1 saved   -> {OUTD/'fig_D1_ecdf.png'}\")\n",
    "\n",
    "\n",
    "# Figure D2: Correlation heatmaps (pooled + per source)\n",
    "def corr_mat(frame, cols):\n",
    "    # Spearman is robust to tail/heavy-tailed marginals\n",
    "    return frame[cols].corr(method=\"spearman\")\n",
    "\n",
    "C_pooled = corr_mat(df, feat_corr)\n",
    "\n",
    "# layout: 2x2 (pooled + first 2 sources), others appended if exist\n",
    "sources = list(df[\"dataset\"].unique())\n",
    "# limit to at most 3 sources for a compact 2x2 grid; if 3, we do pooled + 3 sources in 2x2\n",
    "sources = sources[:min(3, len(sources))]\n",
    "\n",
    "def heat(ax, M, title):\n",
    "    im = ax.imshow(M, vmin=-1, vmax=1, interpolation=\"nearest\")\n",
    "    ax.set_xticks(range(M.shape[1])); ax.set_xticklabels(M.columns, rotation=90)\n",
    "    ax.set_yticks(range(M.shape[0])); ax.set_yticklabels(M.index)\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    for (i,j), v in np.ndenumerate(M.values):\n",
    "        if not np.isnan(v):\n",
    "            ax.text(j, i, f\"{v:.2f}\", ha=\"center\", va=\"center\", fontsize=7)\n",
    "    ax.grid(False)\n",
    "    return im\n",
    "\n",
    "# main heatmaps\n",
    "n_sub = 1 + len(sources)\n",
    "ncols = 2\n",
    "nrows = int(np.ceil(n_sub/ncols))\n",
    "fig2, axes = plt.subplots(nrows, ncols, figsize=(5.5*ncols, 5.5*nrows), dpi=200)\n",
    "axes = np.atleast_1d(axes).ravel()\n",
    "\n",
    "im = heat(axes[0], C_pooled, \"Pooled (Spearman)\")\n",
    "for k, src in enumerate(sources, start=1):\n",
    "    C_src = corr_mat(df[df[\"dataset\"]==src], feat_corr)\n",
    "    heat(axes[k], C_src, f\"{src} (Spearman)\")\n",
    "\n",
    "# colorbar\n",
    "for ax in axes[n_sub:]:\n",
    "    ax.axis(\"off\")\n",
    "cax = fig2.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "cb = fig2.colorbar(axes[0].images[0], cax=cax)\n",
    "cb.set_label(\"Correlation\")\n",
    "\n",
    "fig2.tight_layout(rect=[0,0,0.9,1])\n",
    "fig2.savefig(OUTD/\"fig_D2_corr.png\")\n",
    "plt.close(fig2)\n",
    "print(f\"[OK] Figure D2 saved   -> {OUTD/'fig_D2_corr.png'}\")\n",
    "\n",
    "# Delta-correlation heatmaps (per-source minus pooled) — optional but useful\n",
    "fig3, axes3 = plt.subplots(len(sources), 1, figsize=(6.2, 4.8*len(sources)), dpi=200)\n",
    "if len(sources)==1:\n",
    "    axes3 = [axes3]\n",
    "for ax, src in zip(axes3, sources):\n",
    "    C_src = corr_mat(df[df[\"dataset\"]==src], feat_corr)\n",
    "    D = (C_src - C_pooled).fillna(0)\n",
    "    im = ax.imshow(D, vmin=-1, vmax=1)\n",
    "    ax.set_xticks(range(D.shape[1])); ax.set_xticklabels(D.columns, rotation=90)\n",
    "    ax.set_yticks(range(D.shape[0])); ax.set_yticklabels(D.index)\n",
    "    ax.set_title(f\"delta-Correlation ( {src} - pooled )\", fontsize=11)\n",
    "    for (i,j), v in np.ndenumerate(D.values):\n",
    "        ax.text(j, i, f\"{v:+.2f}\", ha=\"center\", va=\"center\", fontsize=7)\n",
    "cbar = fig3.colorbar(im, ax=axes3, fraction=0.015, pad=0.02)\n",
    "cbar.set_label(\"delta Spearman\")\n",
    "fig3.tight_layout()\n",
    "fig3.savefig(OUTD/\"fig_D2_delta_corr.png\")\n",
    "plt.close(fig3)\n",
    "print(f\"[OK] Figure D2 saved  -> {OUTD/'fig_2_delta_corr.png'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IRP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
